# -*- coding: utf-8 -*-
"""
Created on Wed Dec  8 18:25:00 2021

@author: Chen Xu 
"""


import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
# import tensorflow as tf
from tensorflow import keras
import numpy as np
from scipy.misc import imresize
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import cv2

# from tensorflow.examples.tutorials.mnist import input_data
mnist = tf.keras.datasets.mnist
(train_images, _), (test_images, _) = mnist.load_data()
train_images = train_images / 255.0
test_images = test_images / 255.0


train_image = train_images[:55000]
validation_image = train_images[55000:]

noise_factor = 0.5
batch_size = 128
size = 28
global_step = tf.Variable(0, trainable = False)
LEARNING_RATE_STEP = 55000 // batch_size
learning_rate = tf.train.exponential_decay(0.01, global_step,
    LEARNING_RATE_STEP, 0.95, staircase = True)


# 4f system can be considered as a linear interconection
def sf_system(u, w):
    U = tf.fft2d(u)
    # W=tf.fft2d(w)
    W = tf.fft2d(tf.cast(w, dtype = tf.complex64))
    return tf.ifft2d(U * W)


def make_random(shape):
    return np.random.random(size = shape).astype('float32')


def rang(arr, shape, size = size, base = 28):
    x0 = shape[0] * size // base
    y0 = shape[2] * size // base
    delta = (shape[1] - shape[0]) * size // base
    return arr[x0:x0 + delta, y0:y0 + delta]
    # return arr[shape[0]*size//base:shape[1]*size//base,shape[2]*size//base:shape[3]*size//base]


def reduce_mean(tf_):
    return tf.reduce_mean(tf_)


# def _ten_regions(a):
#     return tf.map_fn(tf.reduce_mean, tf.convert_to_tensor([
#         rang(a, (42, 63, 42, 63)),
#         rang(a, (42, 63, 84, 105)),
#         rang(a, (42, 63, 126, 147)),
#         rang(a, (84, 105, 28, 49)),
#         rang(a, (84, 105, 70, 91)),
#         rang(a, (84, 105, 112, 133)),
#         rang(a, (84, 105, 154, 175)),
#         rang(a, (126, 147, 42, 63)),
#         rang(a, (126, 147, 84, 105)),
#         rang(a, (126, 147, 126, 147))
#     ]))
#
#
# def ten_regions(logits):
#     return tf.map_fn(_ten_regions, tf.abs(logits), dtype = tf.float32)


def download_text(msg, epoch, MIN = 1, MAX = 7, name = ''):
    for i in range(1, 7):
        np.savetxt("{}_Time_{}_layer_{}.txt".format(name, epoch + 1, i), msg[i - 1])
    print("Done")


def download_image(msg, epoch, MIN = 1, MAX = 7, name = ''):
    print(f"Plot images-[{MIN}:{MAX}]")
    for i in range(MIN, MAX):
        # print("Image {}:".format(i))
        plt.figure(dpi = 650.24)
        plt.axis('off')
        plt.grid('off')
        plt.imshow(msg[i - 1])
        plt.savefig("{}_Time_{}_layer_{}.jpg".format(name, epoch + 1, i))
        # print("Done")


def _change(input_):
    return cv2.resize(input_.reshape(size,size),(size*7,size*7),interpolation=cv2.INTER_NEAREST)

def change(input_):
    return np.array(list(map(_change,input_)))


def next_batch(batch_size, fake_data = False, shuffle = True):
    self_images = train_images
    self_epochs_completed = 0
    self_index_in_epoch = 0
    self_num_examples = len(train_images)
    start = self_index_in_epoch
    if self_epochs_completed==0 and start==0 and shuffle:
        perm0 = np.arange(self_num_examples)
        np.random.shuffle(perm0)
        self_images = train_images[perm0]
        # Go to the next epoch


    if start + batch_size > self_num_examples:
        self_epochs_completed += 1
        # Get the rest examples in this epoch
        rest_num_examples = self_num_examples - start
        images_rest_part = self_images[start:self_num_examples]
        # Shuffle the data
        if shuffle:
            perm = np.arange(self_num_examples)
            np.random.shuffle(perm)
            self_images = train_images[perm]
            # Start next epoch

        start = 0
        self_index_in_epoch = batch_size - rest_num_examples
        end = self_index_in_epoch
        images_new_part = self_images[start:end]
        return np.concatenate((images_rest_part, images_new_part), axis = 0)
    else:
        self_index_in_epoch += batch_size
        end = self_index_in_epoch
        return self_images[start:end]


data_x = tf.placeholder(tf.float32, shape = (None, size , size ))
data_y = tf.placeholder(tf.float32, shape = (None, size * 7, size * 7))

# weights
Values = tf.Variable(make_random(shape = (size, size)), dtype = tf.float32)
Keys = tf.Variable(make_random(shape = (size, size)), dtype = tf.float32)
Queries = tf.Variable(make_random(shape = (size, size, 1)), dtype = tf.float32)
weight_1 = tf.Variable(make_random(shape = (size * 7, size * 7)), dtype = tf.float32)
weight_2 = tf.Variable(make_random(shape = (size * 7, size * 7)), dtype = tf.float32)
weight_3 = tf.Variable(make_random(shape = (size * 7, size * 7)), dtype = tf.float32)
# forward propagation
layer1 = tf.abs((tf.tile(data_x, multiples = [1, 7, 7]) * tf.tile(Values, multiples = [7, 7])))
layer2 = tf.abs(layer1 * tf.tile(Keys, multiples = [7, 7]))
layer3 = tf.abs(layer2 * tf.reshape(tf.image.resize(Queries, (196, 196), method = "nearest"), [196, 196]))
layer4 = tf.cast(tf.nn.softmax(tf.abs(sf_system(tf.cast(layer3, dtype = tf.complex64), weight_1))),
    dtype = tf.complex64)
layer5 = tf.cast(tf.nn.softmax(tf.abs(sf_system(tf.cast(layer4, dtype = tf.complex64), weight_2))),
    dtype = tf.complex64)
out = sf_system(layer5, weight_3)

logits_abs = tf.cast(tf.abs(out),dtype =tf.float32)
loss = tf.reduce_mean(0.5*tf.square(logits_abs-data_y))
train_op = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)
# pre_correct = tf.equal(tf.argmax(data_y, 1), tf.argmax(logits_abs, 1))
# accuracy = tf.reduce_mean(tf.cast(pre_correct, tf.float32))

init = tf.global_variables_initializer()
train_epochs = 80
train_loss_list = []
validation_loss_list = []
session = tf.Session()

with tf.device('/gpu:0'):
    session.run(init)
    total_batch = int(len(train_image) / batch_size)

    for epoch in tqdm(range(train_epochs)):
        for batch in tqdm(range(total_batch)):
            batch_target = next_batch(batch_size)
            # Add random noise to the input images
            batch_noise = batch_target + noise_factor * np.random.randn(28, 28)
            batch_noise = np.clip(batch_noise, 0., 1.)

            session.run(train_op, feed_dict = {data_x: batch_noise, data_y: change(batch_target)})

        batch_loss = session.run(loss, feed_dict = {data_x: batch_noise, data_y:change(batch_target)})
        train_loss_list.append(batch_loss)
        print("epoch :{} loss:{:.4f} ".format(epoch + 1, batch_loss))
        # test
        valid_noise = validation_image + noise_factor * np.random.randn(28, 28)
        valid_noise = np.clip(valid_noise, 0., 1.)

        loss_validation = session.run(loss,feed_dict = {data_x: validation_image.reshape((-1, size, size)), data_y: change(validation_image)})
        validation_loss_list.append(loss_validation)

        print("epoch :{} test_loss:{:.4f} ".format(epoch + 1, loss_validation))
print("Optimizer finished")

fig, ax1 = plt.subplots()

Ins = ax1.plot(np.arange(train_epochs), train_loss_list, label = 'training_Loss')

ax1.set_xlabel('interation')
ax1.set_ylabel('training loss')

labels = ['Loss']
plt.legend(Ins, labels, loc = 7)
plt.show()

# weight_= np.array(session.run(weight))
# download_text(weight_,epoch,name='weight')
# download_image(weight_,epoch,name='weight')

fig, ax1 = plt.subplots()
ax2 = ax1.twinx()
Ins_ = ax1.plot(np.arange(train_epochs), validation_loss_list, label = 'Validation_Loss')

ax1.set_xlabel('interation')
ax1.set_ylabel('validation loss')

labels = ['Loss']
plt.legend(Ins_, labels, loc = 7)
plt.show()

